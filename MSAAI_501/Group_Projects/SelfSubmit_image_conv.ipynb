{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image converter\n",
    "\n",
    "### Explination \n",
    "\n",
    "This script is going to take the images that we have and convert them into the black and white format for our model to use. This is going to be done using numpy and a couple other libararies.\n",
    "\n",
    "#### List of Steps\n",
    "\n",
    "1. Getting the Images from the folders Gabe, and Parker's Girlfirend have written the numbers 0-9 on a piece of paper and taken a picture of it. We are going to use these images to test our model. \n",
    "\n",
    "2. We then have to crop the images\n",
    "\n",
    "3. We then have to invert the images, so the background is black and the numbers are white\n",
    "\n",
    "4. We then have to resize the images to be the same format as the MNIST dataset, which is 28x28\n",
    "\n",
    "5. We then have to save the images to a folder that are in the correct format, that are also labled with the number they are supposed to be so when we call the predict function, we can use the labling to see if the model was correct or not, and compare it to the actual number that was written on the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T22:34:16.526090900Z",
     "start_time": "2023-11-26T22:34:15.922244600Z"
    }
   },
   "outputs": [],
   "source": [
    "# import\n",
    "\n",
    "import os \n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T22:34:21.392182200Z",
     "start_time": "2023-11-26T22:34:21.250776300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: 0.png\n",
      "Processing file: 1.png\n",
      "Processing file: 2.png\n",
      "Processing file: 3.png\n",
      "Processing file: 4.png\n",
      "Processing file: 5.png\n",
      "Processing file: 6.png\n",
      "Processing file: 7.png\n",
      "Processing file: 8.png\n",
      "Processing file: 9.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_12188\\1238525548.py:9: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  img = img.resize((28, 28), Image.ANTIALIAS)\n"
     ]
    }
   ],
   "source": [
    "def process_images(input_directory, output_directory):\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "\n",
    "    for filename in os.listdir(input_directory):\n",
    "        if filename.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "            print(f\"Processing file: {filename}\")\n",
    "            img = Image.open(os.path.join(input_directory, filename))\n",
    "            img = img.resize((28, 28), Image.ANTIALIAS)\n",
    "            img = img.convert('L')\n",
    "            img = Image.fromarray(np.invert(np.array(img)))\n",
    "            img.save(os.path.join(output_directory, filename))\n",
    "\n",
    "# directories\n",
    "input_directory = r'C:\\Users\\user\\Desktop\\School\\MSAAI_501\\Group_Projects\\Philips_Numbers'\n",
    "output_directory = r'C:\\Users\\user\\Desktop\\School\\MSAAI_501\\Group_Projects\\Philips_Nums_Formatted'\n",
    "\n",
    "# process and save the images\n",
    "process_images(input_directory, output_directory)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
