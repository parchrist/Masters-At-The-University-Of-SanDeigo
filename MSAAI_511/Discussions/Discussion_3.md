So there are lots of great things about LLM's when you think about the advantages that they have brought to the world thus far. There are lots of things that LLM's are great at such as sequential data, and contextual understanding. But when working with LLM's and their massive data sets, there are lots of problems that come with building them. One of the most common ones is vanishing gradient. The vanishing gradient can really limit the ability of the model. Also when considering that the model is translating long sequences of speech to text, there can be some confusion with the model based off the training data, and what it is trying to predict the best response to be. 

There are a couple of work arounds when dealing with the vanishing gradient problem. One of the first and more straight forward ways which is gradient clipping. Gradient clipping is implemented mostly for the exploding gradient problem, however they can also be used to stop the gradient from diminishing as well. Considering that the implementation does work, there may be a need to have a different model instead of limiting the gradient which brings me to the next solution, LSTM models. LSTM uses a different kind of architecture that helps ensure that the gradients don't become to small or to large, which does make them robust. 

LSTM networks are able to have larger "look backs" which allow them to be able to capture more dependencies for the prediction. For example in the stock market, where if a model was trained on earnings and intra-day pricing, the LSTM model could take hundreds of days, and have a weight, but if the earnings forecast says something else, then the model could have a totally different outcome(GeeksforGeeks, 2023). Also LSTM's have been incorporated in various ways on unstructured data, like text, music and images, which make them a pretty good option when building a model. 

I think that when it comes down to the ability to implement in a desired field, that the model should need to be robust, and have more than one feature. The easiest example I can think of is in the medical field, if a LSTM model is made to look at X-rays, and identify abnormalities, I think that it would also be beneficial to have an additional that is a LLM that can help explain in technical terms what is happening to the doctor/physician. From my understand, is that the medical field has tons of laws surrounding the use of data, and getting ahold of enough X-rays to be able to build a model as described, will be a massive challenge to begin with. However, I am hopeful that one day it will happen. 

References: 
Amanatullah. (2023, June 12). Vanishing gradient problem in Deep learning: understanding, intuition, and solutions. Medium. https://medium.com/@amanatulla1606/vanishing-gradient-problem-in-deep-learning-understanding-intuition-and-solutions-da90ef4ecb54#:~:text=A1%3A%20The%20vanishing%20gradient%20problem,to%20update%20the%20weights%20effectively. 

GeeksforGeeks. (2023, June 5). Understanding of LSTM networks. GeeksforGeeks. https://www.geeksforgeeks.org/understanding-of-lstm-networks/