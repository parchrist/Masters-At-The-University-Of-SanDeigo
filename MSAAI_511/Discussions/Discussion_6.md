Auto encoders are are a type of artificaL neural network that is used to learn data for the purpose of being able to reconize high feature counts, and to be able to utilize demonsonality reduction as well. Sparse encoders work really well when you ar working and trying to understand the sparse representations and what they are meaning. It is able to give you a better understanding of the data that you are working with, and how to adjsut the model and data to get the best results(Dertat, 2018). Denosing autoencoder is encoder that is able to take data and then are able to remove the noise from data and give a better understanding of the data once the "noise" is removed. This can be usefull when you are trying to make the data more clear and easier to understand. An example of this would be if you are working with images and you have a lot of noise in the image, you can use a denosing autoencoder to remove the noise and make the image more clear(Jordan, 2018). A disadvantage of an noise autoencoder is that it can be hard to remove the noise from the data and it can be hard to get the data to be clear and easy to understand. This can be a problem when you are working with data that has a lot of noise in it, and you are trying to make the data more clear and easy to understand. Contractive autoencoders is another type of autoencoder that focuses on very small incremental changes. These models are more stable, and can lead to more accurate represntations. The disadvantage of the contractive autoencoder is that the contractive term makes training time a lot higher and requires more computaions to be done (DeepAI, 2020). The stacked autoencoder is a type of autoencoder that is able to take multiple layers of data and then stacks them to see more complex patterns within the data being presented. The disadvantages of this encoder is that it can be really hard to train, and the more layers that are added to the model, the more complex it becomes. Lastly the deep autoencoder is a more complex version of the stacked autoencoder, and they are really good at making very complex patterns within the data. 

When thinking about the type of encoder that you should choose, you have to think about a couple of things. For example the type of data that you are working with plays a big part in the type of encoder you should pick, and if you're working with structured data or unstructured data. You should also be thinking about the problem you are trying to solve. Another example of when to use an Noise autoencoder is when you are working with images and you have a lot of noise in the image, you can use a denosing autoencoder to remove the noise and make the image more clear. This can be usefull when you are trying to make the data more clear and easier to understand, or even trying to bring the resolution of the image up.


References:

DeepAI. (2020, June 25). Contractive Autoencoder. DeepAI. https://deepai.org/machine-learning-glossary-and-terms/contractive-autoencoder 

Dertat, A. (2018, June 21). Applied Deep Learning - Part 3: Autoencoders - towards Data science. Medium. https://towardsdatascience.com/applied-deep-learning-part-3-autoencoders-1c083af4d798 Jordan, J. (2018, March 19). 

Introduction to autoencoders. Jeremy Jordan. https://www.jeremyjordan.me/autoencoders/
