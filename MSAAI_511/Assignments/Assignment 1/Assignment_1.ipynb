{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Assignment 1.1`\n",
    "### Tensor Operations in TensorFlow and PyTorch\n",
    "\n",
    "In this assignment, you will focus on developing and implementing math operations on tensors of different dimensions in TensorFlow and PyTorch. You will be developing and implementing basic math operations on one-, two-, and three-dimensional tensors in TensorFlow and PyTorch. This will include creating and manipulating tensors, performing arithmetic operations on tensors, and exploring the use of functions that operate on tensors. For this assignment, you can use a Jupyter Notebook or a Python script.\n",
    "\n",
    "___\n",
    "\n",
    "#### `Part 1 of the Assignment: Tensor Operations`\n",
    "\n",
    "1. Create a one-dimensional tensor in both TensorFlow and PyTorch that contains the values of your interest. Print the tensor to the console for each framework.\n",
    "2. Create a two-dimensional tensor in both TensorFlow and PyTorch that contains the values of your interest. Print the tensor to the console for each framework.\n",
    "3. Create a three-dimensional tensor in both TensorFlow and PyTorch that contains the values of your interest. Print the tensor to the console for each framework.\n",
    "4. Create a function in both TensorFlow and PyTorch that takes two tensors as input and returns the sum of their elements. Test the function with 1D, 2D, and 3D tensors. This function will demonstrate how to perform element-wise addition between two tensors and then sum all elements of the resulting tensor.\n",
    "\n",
    "____\n",
    "\n",
    "#### `Part 2 of the Assignment: The Role of Broadcasting in Tensor Operations`\n",
    "\n",
    "- Broadcasting is a powerful mechanism that allows TensorFlow and PyTorch to work with tensors of different shapes during arithmetic operations.\n",
    "1. Describe how broadcasting works in tensor operations, providing a simple example to illustrate your explanation.\n",
    "2. Discuss why broadcasting is important and how it enhances the flexibility of tensor operations in building neural network models.\n",
    "3. Explain what limitations or challenges might arise when relying on broadcasting, particularly in the context of ensuring model correctness and efficiency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing tensorflow keras numpy and pytorch\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import torch\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors in TF and PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a 1D tensor in tensorflow \n",
    "tf_1d = tf.constant([1, 2, 3, 4, 5])\n",
    "\n",
    "# creating a 2D tensor in tensorflow\n",
    "tf_2d = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "# creating a 3d tensor in tensorflow\n",
    "tf_3d = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a 1D tensor in pytorch\n",
    "d2_t = torch.tensor([1, 2, 3, 4, 5])\n",
    "\n",
    "# createing a 2D tensor in pytorch\n",
    "d2_t = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "# creating a 3D tensor in pytorch\n",
    "d3_t = torch.tensor([[[1, 2, 3], [4, 5, 6], [7, 8, 9]]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor flow function\n",
    "\n",
    "def tf_function(tensor1, tensor2):\n",
    "    summed_tensor = tf.add(tensor1, tensor2)\n",
    "    return tf.reduce_sum(summed_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the sum of the 1D tensor is:  tf.Tensor(30, shape=(), dtype=int32)\n",
      "the sum of the 2D tensor is:  tf.Tensor(90, shape=(), dtype=int32)\n",
      "the sum of the 3D tensor is:  tf.Tensor(156, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# testing the function\n",
    "tensor_1d_tf = tf.constant([1, 2, 3, 4, 5])\n",
    "tensor_1d_tf_2 = tf.constant([5, 4, 3, 2, 1])\n",
    "\n",
    "tensor_2d_tf = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "tensor_2d_tf_2 = tf.constant([[9, 8, 7], [6, 5, 4], [3, 2, 1]])\n",
    "\n",
    "tensor_3d_tf = tf.constant([[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]])\n",
    "tensor_3d_tf_2 = tf.constant([[[12, 11, 10], [9, 8, 7]], [[6, 5, 4], [3, 2, 1]]])\n",
    "\n",
    "# printing the results\n",
    "print(\"the sum of the 1D tensor is: \", tf_function(tensor_1d_tf, tensor_1d_tf_2))\n",
    "print(\"the sum of the 2D tensor is: \", tf_function(tensor_2d_tf, tensor_2d_tf_2))\n",
    "print(\"the sum of the 3D tensor is: \", tf_function(tensor_3d_tf, tensor_3d_tf_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch function\n",
    "\n",
    "def torch_function(tensor1, tensor2):\n",
    "    summed_tensor = torch.add(tensor1, tensor2)\n",
    "    return torch.sum(summed_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the sum of the 1D tensor is:  tensor(30)\n",
      "the sum of the 2D tensor is:  tensor(90)\n",
      "the sum of the 3D tensor is:  tensor(156)\n"
     ]
    }
   ],
   "source": [
    "# testing the function\n",
    "tensor_1d_torch = torch.tensor([1, 2, 3, 4, 5])\n",
    "tensor_1d_torch_2 = torch.tensor([5, 4, 3, 2, 1])\n",
    "\n",
    "tensor_2d_torch = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "tensor_2d_torch_2 = torch.tensor([[9, 8, 7], [6, 5, 4], [3, 2, 1]])\n",
    "\n",
    "tensor_3d_torch = torch.tensor([[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]])\n",
    "tensor_3d_torch_2 = torch.tensor([[[12, 11, 10], [9, 8, 7]], [[6, 5, 4], [3, 2, 1]]])\n",
    "\n",
    "# printing the results\n",
    "print(\"the sum of the 1D tensor is: \", torch_function(tensor_1d_torch, tensor_1d_torch_2))\n",
    "print(\"the sum of the 2D tensor is: \", torch_function(tensor_2d_torch, tensor_2d_torch_2))\n",
    "print(\"the sum of the 3D tensor is: \", torch_function(tensor_3d_torch, tensor_3d_torch_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Broadcasting in Tensor Operations**\n",
    "___\n",
    "\n",
    "\n",
    "#### `1. Describe how broadcasting works in tensor operations, providing a simple example to illustrate your explanation.`\n",
    "\n",
    "- Broadcasting in tensor operations is when one tensor is expanded to match the shape of another tensor so that the operation can be performed. The tensors are then comared element-wise from the trailing dimension. If the dimensions are equal or one of the dimensions is 1, the tensors are compatible. If the dimensions are not equal and one of the dimensions is not 1, the tensors are not compatible.\n",
    "\n",
    "\n",
    "\n",
    "#### `2. Discuss why broadcasting is important and how it enhances the flexibility of tensor operations in building neural network models.`\n",
    "\n",
    "- The advantage of broadcasting is that it allows for the flexibility of working with tensors of different shapes during arithmetic operations. This is important because it allows for the simplification of code and the reduction of memory usage. It also allows for the reduction of the number of loops needed to perform the operation. When using broacasting the neural network is able to simplify the forward and backward passes, by allowing for the operation to be performed on tensors of different shapes. Another advantage is that it allows for batch processing of data, which is important for training neural networks, a 1D bias tensor can be added to a 2D tensor of weights.\n",
    "\n",
    "#### `3. Explain what limitations or challenges might arise when relying on broadcasting, particularly in the context of ensuring model correctness and efficiency.`\n",
    "\n",
    "- The first one that comes to my mind is when two tensors are incompatable shape wise. This can lead to errors in the code, and cause hours of debugging. Another thing that is a possibility when working on and with tensors is that there could be some unpredicable behavour that occurs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ternsor 1: \n",
      "  tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]]) \n",
      "\n",
      "Tensor 2: \n",
      "  tensor([4, 5, 6]) \n",
      "\n",
      "Result: \n",
      "  tensor([[ 5,  7,  9],\n",
      "        [ 8, 10, 12],\n",
      "        [11, 13, 15]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tensor Broadcasting\n",
    "\n",
    "tensor1 = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "tensor2 = torch.tensor([4, 5, 6])\n",
    "\n",
    "'''\n",
    "We have tensor 1 with shape (3, 3) and tensor 2 with shape (3,) and we are just going to add them together. So tensor 2 will be applied to every axis of tensor 1. \n",
    "'''\n",
    "\n",
    "result = tensor1 + tensor2\n",
    "\n",
    "\n",
    "print(\"Ternsor 1: \\n \", tensor1,\"\\n\")\n",
    "\n",
    "print(\"Tensor 2: \\n \", tensor2,\"\\n\")\n",
    "\n",
    "print(\"Result: \\n \", result,\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
